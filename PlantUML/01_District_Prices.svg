<?xml version="1.0" encoding="UTF-8" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentScriptType="application/ecmascript" contentStyleType="text/css" height="1199px" preserveAspectRatio="none" style="width:786px;height:1199px;" version="1.1" viewBox="0 0 786 1199" width="786px" zoomAndPan="magnify"><defs><filter height="300%" id="f18pcnrspgxs0s" width="300%" x="-1" y="-1"><feGaussianBlur result="blurOut" stdDeviation="2.0"/><feColorMatrix in="blurOut" result="blurOut2" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 .4 0"/><feOffset dx="4.0" dy="4.0" in="blurOut2" result="blurOut3"/><feBlend in="SourceGraphic" in2="blurOut3" mode="normal"/></filter></defs><g><!--cluster fetch_housing_data( )--><polygon fill="#D3D3D3" filter="url(#f18pcnrspgxs0s)" points="273,44,432,44,439,67.6094,471,67.6094,471,146,273,146,273,44" style="stroke: #303030; stroke-width: 1.5;"/><line style="stroke: #303030; stroke-width: 1.5;" x1="273" x2="439" y1="67.6094" y2="67.6094"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="153" x="277" y="60.5332">fetch_housing_data( )</text><!--cluster load_housing_data()--><polygon fill="#D3D3D3" filter="url(#f18pcnrspgxs0s)" points="257,170,406,170,413,193.6094,487,193.6094,487,272,257,272,257,170" style="stroke: #303030; stroke-width: 1.5;"/><line style="stroke: #303030; stroke-width: 1.5;" x1="257" x2="413" y1="193.6094" y2="193.6094"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="143" x="261" y="186.5332">load_housing_data()</text><!--cluster ColumnTransformer( )--><polygon fill="#D3D3D3" filter="url(#f18pcnrspgxs0s)" points="252,296,411,296,418,319.6094,764,319.6094,764,769,252,769,252,296" style="stroke: #303030; stroke-width: 1.5;"/><line style="stroke: #303030; stroke-width: 1.5;" x1="252" x2="418" y1="319.6094" y2="319.6094"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="153" x="256" y="312.5332">ColumnTransformer( )</text><!--cluster Pipeline( )--><polygon fill="#90EE90" filter="url(#f18pcnrspgxs0s)" points="276,340,353,340,360,363.6094,740,363.6094,740,664,276,664,276,340" style="stroke: #303030; stroke-width: 1.5;"/><line style="stroke: #303030; stroke-width: 1.5;" x1="276" x2="360" y1="363.6094" y2="363.6094"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="71" x="280" y="356.5332">Pipeline( )</text><!--cluster CombinedAttributesAdder( )--><polygon fill="#ADD8E6" filter="url(#f18pcnrspgxs0s)" points="300,457,502,457,509,480.6094,616,480.6094,616,574,300,574,300,457" style="stroke: #303030; stroke-width: 1.5;"/><line style="stroke: #303030; stroke-width: 1.5;" x1="300" x2="509" y1="480.6094" y2="480.6094"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="196" x="304" y="473.5332">CombinedAttributesAdder( )</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="165" x="289.5" y="80"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="143" x="300.5" y="102.457">Pull a copy of the data and</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="145" x="299.5" y="117.5508">extract it to a local directory</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="197" x="273.5" y="206"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="120" x="312" y="228.457">Extract data from local</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="73" x="283.5" y="243.5508">directory as a</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="42" x="359.5" y="243.5508">Pandas</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="56" x="404.5" y="243.5508">dataframe</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="311" x="279.5" y="688"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="174" x="302" y="710.457">Encodes categorical data with a</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="89" x="479" y="710.457">OneHotEncoder</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="291" x="289.5" y="725.5508">creating a sparse matrix with 1s in the position where</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="269" x="300.5" y="740.6445">a category is present and 0s in all other positions</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="224" x="292" y="376"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="196" x="306" y="398.457">Passes the training data through an</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="44" x="316" y="413.5508">Imputer</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="129" x="363" y="413.5508">filling in missing values</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="204" x="302" y="428.6445">with the median value of that category</text><path d="M536.5,378.5 L536.5,404.5 L516.117,408.5 L536.5,412.5 L536.5,438.8125 A0,0 0 0 0 536.5,438.8125 L723.5,438.8125 A0,0 0 0 0 723.5,438.8125 L723.5,388.5 L713.5,378.5 L536.5,378.5 A0,0 0 0 0 536.5,378.5 " fill="#CEEEFE" filter="url(#f18pcnrspgxs0s)" style="stroke: #303030; stroke-width: 1.0;"/><path d="M713.5,378.5 L713.5,388.5 L723.5,388.5 L713.5,378.5 " fill="#CEEEFE" style="stroke: #303030; stroke-width: 1.0;"/><text fill="#000000" font-family="sans-serif" font-size="10" lengthAdjust="spacingAndGlyphs" textLength="143" x="542.5" y="393.8809">All operation in the Pipeline( )</text><text fill="#000000" font-family="sans-serif" font-size="10" lengthAdjust="spacingAndGlyphs" textLength="134" x="542.5" y="406.459">function operate only on the</text><text fill="#000000" font-family="sans-serif" font-size="10" lengthAdjust="spacingAndGlyphs" textLength="145" x="542.5" y="419.0371">numeric categories, text-based</text><text fill="#000000" font-family="sans-serif" font-size="10" lengthAdjust="spacingAndGlyphs" textLength="166" x="542.5" y="431.6152">categories are dealt with afterwards</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="288" x="303" y="598"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="139" x="331.5" y="620.457">Scales the data using the</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="89" x="473.5" y="620.457">StandardScaler</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="97" x="313" y="635.5508">which computes (</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="24" x="410" y="635.5508">data</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="4" x="437" y="635.5508">-</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="70" x="444" y="635.5508">data.mean( )</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="10" x="514" y="635.5508">) /</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="54" x="527" y="635.5508">data.std( )</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="283" x="316.5" y="493"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="255" x="330.5" y="515.457">Append additional categories as combinations</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="263" x="326.5" y="530.5508">of other existing categories that may have higher</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="251" x="332.5" y="545.6445">correlation coeficients with the target category.</text><ellipse cx="149" cy="18" fill="#000000" filter="url(#f18pcnrspgxs0s)" rx="10" ry="10" style="stroke: none; stroke-width: 1.0;"/><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="215" x="41.5" y="80"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="195" x="51.5" y="102.457">Set path to repository containing the</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="190" x="54" y="117.5508">relevant dataset for this application</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="226" x="15" y="198.5"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="197" x="29.5" y="220.957">Use increments of $10,000 from the</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="90" x="25" y="236.0508">median_income</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="113" x="118" y="236.0508">category to create an</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="205" x="25.5" y="251.1445">80/20 split of training and testing data</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="216" x="20" y="376"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="24" x="30" y="398.457">Split</text><text fill="#000000" font-family="sans-serif" font-size="12" font-style="italic" lengthAdjust="spacingAndGlyphs" textLength="120" x="57" y="398.457">median_house_value</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="46" x="180" y="398.457">category</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="191" x="32.5" y="413.5508">from the training data, this category</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="169" x="43.5" y="428.6445">will serve as the training labels</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="181" x="54.5" y="695.5"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="161" x="64.5" y="717.957">Evaluate model performance:</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="101" x="94.5" y="733.0508">LinearRegression</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="181" x="54.5" y="793"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="161" x="64.5" y="815.457">Evaluate model performance:</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="135" x="77.5" y="830.5508">DecisionTreeRegressor</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="50.1875" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="181" x="54.5" y="883"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="161" x="64.5" y="905.457">Evaluate model performance:</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="143" x="73.5" y="920.5508">RandomForestRegressor</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="65.2813" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="253" x="18.5" y="973"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="51" x="37.5" y="995.457">Leverage</text><text fill="#000000" font-family="sans-serif" font-size="12" font-weight="bold" lengthAdjust="spacingAndGlyphs" textLength="80" x="91.5" y="995.457">GridSearchCV</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="78" x="174.5" y="995.457">to run multiple</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="190" x="50" y="1010.5508">tests with different combinations of</text><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="233" x="28.5" y="1025.6445">hyperparameters to find the optimal values</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="35.0938" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="271" x="9.5" y="1078"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="251" x="19.5" y="1100.457">Evaluate model with optimal hyperparameters</text><rect fill="#FFEFD5" filter="url(#f18pcnrspgxs0s)" height="35.0938" rx="12.5" ry="12.5" style="stroke: #303030; stroke-width: 1.5;" width="278" x="6" y="1153"/><text fill="#000000" font-family="sans-serif" font-size="12" lengthAdjust="spacingAndGlyphs" textLength="258" x="16" y="1175.457">Computer confidence intervance for predictions</text><!--link start to Set path to repository containing the\nrelevant dataset for this application--><path d="M149,28.1 C149,39.1 149,58.18 149,74.45 " fill="none" id="start-Set path to repository containing the\nrelevant dataset for this application" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="149,79.85,153,70.85,149,74.85,145,70.85,149,79.85" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Set path to repository containing the\nrelevant dataset for this application to Pull a copy of the data and\nextract it to a local directory--><path d="M256.58,105 C265.837,105 275.093,105 284.35,105 " fill="none" id="Set path to repository containing the\nrelevant dataset for this application-Pull a copy of the data and\nextract it to a local directory" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="289.493,105,280.493,101,284.493,105,280.493,109,289.493,105" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Pull a copy of the data and\nextract it to a local directory to Extract data from local\ndirectory as a //Pandas// dataframe--><path d="M372,130.2 C372,150.43 372,179.34 372,200.838 " fill="none" id="Pull a copy of the data and\nextract it to a local directory-Extract data from local\ndirectory as a //Pandas// dataframe" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="372,205.858,376,196.858,372,200.858,368,196.858,372,205.858" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Use increments of $10,000 from the\n//median_income// category to create an\n80/20 split of training and testing data to Extract data from local\ndirectory as a //Pandas// dataframe--><path d="M246.901,231 C255.701,231 264.501,231 273.301,231 " fill="none" id="Use increments of $10,000 from the\n//median_income// category to create an\n80/20 split of training and testing data-Extract data from local\ndirectory as a //Pandas// dataframe" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="241.422,231,250.422,235,246.422,231,250.422,227,241.422,231" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Use increments of $10,000 from the\n//median_income// category to create an\n80/20 split of training and testing data to Split //median_house_value// category\nfrom the training data, this category\nwill serve as the training labels--><path d="M128,263.782 C128,293.849 128,338.962 128,370.604 " fill="none" id="Use increments of $10,000 from the\n//median_income// category to create an\n80/20 split of training and testing data-Split //median_house_value// category\nfrom the training data, this category\nwill serve as the training labels" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="128,375.955,132,366.955,128,370.955,124,366.955,128,375.955" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Split //median_house_value// category\nfrom the training data, this category\nwill serve as the training labels to Passes the training data through an\n**Imputer** filling in missing values\nwith the median value of that category--><path d="M236.082,408.5 C252.924,408.5 269.767,408.5 286.609,408.5 " fill="none" id="Split //median_house_value// category\nfrom the training data, this category\nwill serve as the training labels-Passes the training data through an\n**Imputer** filling in missing values\nwith the median value of that category" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="291.836,408.5,282.836,404.5,286.836,408.5,282.836,412.5,291.836,408.5" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Passes the training data through an\n**Imputer** filling in missing values\nwith the median value of that category to Append additional categories as combinations\nof other existing categories that may have higher\ncorrelation coeficients with the target category.--><path d="M418.899,441.229 C425.745,455.809 433.901,473.177 440.988,488.27 " fill="none" id="Passes the training data through an\n**Imputer** filling in missing values\nwith the median value of that category-Append additional categories as combinations\nof other existing categories that may have higher\ncorrelation coeficients with the target category." style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="443.15,492.875,442.9443,483.0283,441.0243,488.3494,435.7033,486.4294,443.15,492.875" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Append additional categories as combinations\nof other existing categories that may have higher\ncorrelation coeficients with the target category. to Scales the data using the **StandardScaler**\nwhich computes (//data// - //data.mean( )//) / //data.std( )//--><path d="M454.368,558.035 C453.088,569.147 451.655,581.589 450.395,592.525 " fill="none" id="Append additional categories as combinations\nof other existing categories that may have higher\ncorrelation coeficients with the target category.-Scales the data using the **StandardScaler**\nwhich computes (//data// - //data.mean( )//) / //data.std( )//" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="449.792,597.76,454.7968,589.2775,450.3648,592.7929,446.8495,588.361,449.792,597.76" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Scales the data using the **StandardScaler**\nwhich computes (//data// - //data.mean( )//) / //data.std( )// to Encodes categorical data with a **OneHotEncoder**\ncreating a sparse matrix with 1s in the position where\na category is present and 0s in all other positions--><path d="M443.972,648.099 C442.659,658.545 441.093,671.011 439.639,682.582 " fill="none" id="Scales the data using the **StandardScaler**\nwhich computes (//data// - //data.mean( )//) / //data.std( )//-Encodes categorical data with a **OneHotEncoder**\ncreating a sparse matrix with 1s in the position where\na category is present and 0s in all other positions" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="438.98,687.824,444.0699,679.3923,439.6028,682.8629,436.1322,678.3958,438.98,687.824" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Evaluate model performance:\n**LinearRegression** to Encodes categorical data with a **OneHotEncoder**\ncreating a sparse matrix with 1s in the position where\na category is present and 0s in all other positions--><path d="M240.736,720.5 C253.57,720.5 266.404,720.5 279.238,720.5 " fill="none" id="Evaluate model performance:\n**LinearRegression**-Encodes categorical data with a **OneHotEncoder**\ncreating a sparse matrix with 1s in the position where\na category is present and 0s in all other positions" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="235.625,720.5,244.625,724.5,240.625,720.5,244.625,716.5,235.625,720.5" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Evaluate model performance:\n**LinearRegression** to Evaluate model performance:\n**DecisionTreeRegressor**--><path d="M145,745.599 C145,758.379 145,774.184 145,787.672 " fill="none" id="Evaluate model performance:\n**LinearRegression**-Evaluate model performance:\n**DecisionTreeRegressor**" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="145,792.909,149,783.909,145,787.909,141,783.909,145,792.909" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Evaluate model performance:\n**DecisionTreeRegressor** to Evaluate model performance:\n**RandomForestRegressor**--><path d="M145,843.046 C145,853.814 145,866.605 145,877.907 " fill="none" id="Evaluate model performance:\n**DecisionTreeRegressor**-Evaluate model performance:\n**RandomForestRegressor**" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="145,882.983,149,873.983,145,877.983,141,873.983,145,882.983" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Evaluate model performance:\n**RandomForestRegressor** to Leverage **GridSearchCV** to run multiple\ntests with different combinations of\nhyperparameters to find the optimal values--><path d="M145,933.099 C145,943.545 145,956.011 145,967.582 " fill="none" id="Evaluate model performance:\n**RandomForestRegressor**-Leverage **GridSearchCV** to run multiple\ntests with different combinations of\nhyperparameters to find the optimal values" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="145,972.824,149,963.824,145,967.824,141,963.824,145,972.824" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Leverage **GridSearchCV** to run multiple\ntests with different combinations of\nhyperparameters to find the optimal values to Evaluate model with optimal hyperparameters--><path d="M145,1038.27 C145,1049.673 145,1062.267 145,1072.64 " fill="none" id="Leverage **GridSearchCV** to run multiple\ntests with different combinations of\nhyperparameters to find the optimal values-Evaluate model with optimal hyperparameters" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="145,1077.844,149,1068.844,145,1072.844,141,1068.844,145,1077.844" style="stroke: #6495ED; stroke-width: 1.0;"/><!--link Evaluate model with optimal hyperparameters to Computer confidence intervance for predictions--><path d="M145,1113.0648 C145,1123.2594 145,1136.4469 145,1147.5101 " fill="none" id="Evaluate model with optimal hyperparameters-Computer confidence intervance for predictions" style="stroke: #6495ED; stroke-width: 1.0;"/><polygon fill="#6495ED" points="145,1152.748,149,1143.748,145,1147.748,141,1143.748,145,1152.748" style="stroke: #6495ED; stroke-width: 1.0;"/><!--
@startuml

skinparam Activity {
	ArrowColor		#6495ED
	ArrowFontSize	10
	BorderColor		#303030
	BackgroundColor	#FFEFD5
}

skinparam Package {
	StartColor					#303030
	EndColor					#303030
	BackgroundColor				#D3D3D3
	BackgroundColor<<Failure>>	#FEA0A0
	BackgroundColor<<Success>>	#A0FEA0
	BorderColor					#303030
	ArrowColor					#4169E1
	FontStyle					bold
}

SkinParam Class {
    HeaderBackgroundColor	#D3D3D3
    ArrowColor				#6495ED
    BorderColor				#303030
    BackgroundColor			#FFEFD5
    FontSize				10
}

skinparam Note {
	BorderColor		#303030
	BackgroundColor	#CEEEFE
	FontSize		10
}

(*) - -> "Set path to repository containing the 
		relevant dataset for this application"

partition "fetch_housing_data( )" {
	-> "Pull a copy of the data and 
		extract it to a local directory"
}

partition "load_housing_data()" {
	- -> "Extract data from local 
		directory as a //Pandas// dataframe"
}

-left-> "Use increments of $10,000 from the 
		//median_income// category to create an 
		80/20 split of training and testing data"

- -> "Split //median_house_value// category 
	from the training data, this category 
	will serve as the training labels"

partition "ColumnTransformer( )" {
	partition "Pipeline( )" #LightGreen {
	
		-> "Passes the training data through an 
			**Imputer** filling in missing values 
			with the median value of that category"
		
		note right
			All operation in the Pipeline( ) 
			function operate only on the 
			numeric categories, text-based 
			categories are dealt with afterwards
		end note
	
		partition "CombinedAttributesAdder( )" #LightBlue {
			- -> "Append additional categories as combinations 
				of other existing categories that may have higher 
				correlation coeficients with the target category."
		}
		
		- -> "Scales the data using the **StandardScaler**
			which computes (//data// - //data.mean( )//) / //data.std( )//"
	}
	
	- -> "Encodes categorical data with a **OneHotEncoder**
		creating a sparse matrix with 1s in the position where 
		a category is present and 0s in all other positions"
}

-left-> "Evaluate model performance: 
		**LinearRegression**"
		
- -> "Evaluate model performance: 
	**DecisionTreeRegressor**"
	
- -> "Evaluate model performance: 
	**RandomForestRegressor**"
	
- -> "Leverage **GridSearchCV** to run multiple 
	tests with different combinations of 
	hyperparameters to find the optimal values"
	
- -> "Evaluate model with optimal hyperparameters"

- -> "Computer confidence intervance for predictions"

@enduml

PlantUML version 1.2018.12(Sun Oct 21 05:15:15 CDT 2018)
(GPL source distribution)
Java Runtime: Java(TM) SE Runtime Environment
JVM: Java HotSpot(TM) 64-Bit Server VM
Java Version: 1.8.0_181-b13
Operating System: Windows 10
OS Version: 10.0
Default Encoding: Cp1252
Language: en
Country: US
--></g></svg>